{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import Phylo\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given an array of form:  \n",
    "$[[parent_k,child_k,branchlength_k\\ for\\ k\\ pairs\\ in\\ tree_i]\\ for\\ i\\ trees]$  \n",
    "1. Transform branch lengths to proportions of tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_depth(tree):\n",
    "    '''given a tree in newick format, return overall depth'''\n",
    "    \n",
    "    tree = Phylo( io.StringIO(tree), 'newick')\n",
    "    max_depth = max(tree.depths().values())\n",
    "    \n",
    "    return max_depth\n",
    "\n",
    "def branch_ratio(data, tree_data, index):\n",
    "    '''given a data_row with form [[parent ,child, branch_length]],\n",
    "    return data_row with ratios of branch lengths'''\n",
    "    \n",
    "    tree = tree_data[tree_data['dreamID'] == index]['ground'].item()\n",
    "    max_depth = tree_depth(tree)\n",
    "    transformed_data = data #initialize\n",
    "    for i in range(data):\n",
    "        transformed_data[i][2] = data[i][2] / max_depth\n",
    "    \n",
    "    return transformed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert Parent,Child pairs to 20x1 mutation array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trit_det(parent, child):\n",
    "    '''Given two trits from parent node 1 and child node 2 joined by an edge,\n",
    "    return list alpha,beta determining mutation'''\n",
    "    \n",
    "    if parent == '1':\n",
    "        if child == '2':#1->2\n",
    "            alpha,beta = 0,1\n",
    "        else:#1->0\n",
    "            alpha,beta = 1,0\n",
    "    else:#no mutation\n",
    "        alpha,beta = 0,0\n",
    "    \n",
    "    return [alpha,beta]\n",
    "\n",
    "def barcode_det(parent, child):\n",
    "    '''Given two barcodes from parent node 1 and child node 2 joined by an edge,\n",
    "    return 10x2 array with rows alpha_i beta_i'''\n",
    "    \n",
    "    alpha_beta_array = np.zeros((10,2))\n",
    "    for i in range(10):\n",
    "        alpha_beta_array[i, :] = trit_det(parent[i], child[i])\n",
    "    \n",
    "    return alpha_beta_array\n",
    "\n",
    "def convert_pair(tree):\n",
    "    '''Given a data row of form [[parent,child,branch_length]]\n",
    "    return row of form [1x20 mutations, branch_length]'''\n",
    "    \n",
    "    converted_tree = []#initialize\n",
    "    for pair in tree:\n",
    "        mut_array = barcode_det(pair[0], pair[1]).reshape((1, 20))\n",
    "        converted_pair = [mut_array, pair[2]]\n",
    "        converted_tree.append(converted_pair)\n",
    "    \n",
    "    return converted_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reformat data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DREAM_data = pd.read_csv('\\data\\Dream_data_intMemoir.csv', sep = '\\t')\n",
    "DREAM_train = DREAM_data[30:]\n",
    "DREAM_test = DREAM_data[:30]\n",
    "\n",
    "test_data = 'mayas'\n",
    "train_data = 'mayas_too'\n",
    "\n",
    "reformat_train = np.zeros(train_data.shape)\n",
    "reformat_test = np.zeros(test_data.shape)\n",
    "\n",
    "reformat_pair = [reformat_train, reformat_test]\n",
    "DREAM_pair = [DREAM_train, DREAM_test]\n",
    "data_pair = [train_data, test_data]\n",
    "\n",
    "\n",
    "for k in range(2): #0 = train, 1 = test\n",
    "    for i in range(data_pair[k].shape[0]):\n",
    "        tree_row = data_pair[k][i]\n",
    "        tree_row = branch_ratio(tree_row, DREAM_pair[k], i)\n",
    "        reformat_row = convert_pair(tree_row)\n",
    "        reformat_pair[k][i] = reformat_row\n",
    "\n",
    "#split data from labels\n",
    "train_input, train_label = reformat_train[:, 0], reformat_train[:, 1]\n",
    "test_input, test_label = reformat_test[:, 0], reformat_test[:, 1]\n",
    "\n",
    "#tbd: conversion to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class model(nn.Module):\n",
    "    '''1 layer (FC) Neural Network'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''Define model module'''\n",
    "        super(model, self).__init__()\n",
    "        self.fc = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Define model activation'''\n",
    "        return F.sigmoid(self.fc(x))\n",
    "\n",
    "BRANCH_MODEL = model()\n",
    "print(BRANCH_MODEL)\n",
    "#define the optimizer\n",
    "optimizer = optim.SGD(BRANCH_MODEL.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d6ef9b64b236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "train_epoch_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS+1):\n",
    "    train_loss = []\n",
    "    \n",
    "    #here train_set is the dataset of trees\n",
    "    #each index correlates with set of [alpha_beta_array,branchlength]\n",
    "    #at this point branch length needs to be normalized\n",
    "    #for given tree \n",
    "    for train_loader in train_set: #this would correlate with a DataLoader object\n",
    "\n",
    "        for batch_index, (train_data, train_label) in enumerate(train_loader):\n",
    "            \n",
    "            BRANCH_MODEL.train()\n",
    "            train_label_predicted = BRANCH_MODEL(train_data)\n",
    "            \n",
    "            #compute the loss\n",
    "            loss = F.smooth_l1_loss(train_label_predicted, train_label)\n",
    "            train_loss.append(loss.cpu().data.item())\n",
    "            \n",
    "            #reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "            #backpropagate the loss\n",
    "            loss.backward()\n",
    "            #update the parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_epoch_loss.append(np.mean(train_loss))\n",
    "        \n",
    "        if epoch%5 == 0:\n",
    "            print(\"Epoch: {} | train_loss: {}\".format(epoch, train_epoch_loss[-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
