{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import Phylo\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents  \n",
    "1. [Preproccess](#preproccess)  \n",
    "2. [Model Defintion](#model)  \n",
    "3. [Training](#train)  \n",
    "4. [Evaluation](#eval)  \n",
    "5. [Branch Function Setup](#function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preproccess\n",
    "<a id = 'preprocess'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Functions for Network Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to be applied tree-wise\n",
    "def tree_depth(tree):\n",
    "    '''given a tree in newick format, return overall depth'''\n",
    "    \n",
    "    tree = Phylo.read(io.StringIO(tree), 'newick')\n",
    "    max_depth = max(tree.depths().values())\n",
    "    \n",
    "    return max_depth\n",
    "\n",
    "def branch_ratio(data, tree_data, index):\n",
    "    '''given a data_row with form [[parent ,child, branch_length]],\n",
    "    return data_row with ratios of branch lengths'''\n",
    "    \n",
    "    tree = tree_data[tree_data['dreamID'] == index]['ground'].item()\n",
    "    max_depth = tree_depth(tree)\n",
    "    \n",
    "    transformed_data = data #initialize\n",
    "    for i in range(len(data)):\n",
    "        transformed_data[i][2] = data[i][2] / max_depth\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to be applied trit-wise\n",
    "def trit_det(parent, child):\n",
    "    '''Given two trits from parent node 1 and child node 2 joined by an edge,\n",
    "    return labeled mutation:\n",
    "    1 -> 2 = 0\n",
    "    1 -> 0 = 1\n",
    "    1 -> 1 (no change) = 2\n",
    "    2 -> 2/ 0 -> 0 (no change) = 2\n",
    "    '''\n",
    "    \n",
    "    if parent == '1':\n",
    "        if child == '2':#1->2\n",
    "            return 0\n",
    "        elif child == '0':#1->0\n",
    "            return 1\n",
    "        else: #'1' -> '1'\n",
    "            return 2\n",
    "    else:#no mutation\n",
    "        return 2\n",
    "\n",
    "def barcode_det(parent, child):\n",
    "    '''Given two barcodes from parent node 1 and child node 2 joined by an edge,\n",
    "    return a 10x3 with 0, 1, 2'''\n",
    "    \n",
    "    parent = str(parent)\n",
    "    child = str(child)\n",
    "    mutation_vector = [trit_det(parent[i],child[i]) for i in range(10)]\n",
    "    \n",
    "    mutation_array = np.zeros((10, 3))#10 trites, 3 categories\n",
    "    for i in range(10):\n",
    "        mutation_array[i, mutation_vector[i]] = 1\n",
    "    \n",
    "    return mutation_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Processing of  Data, TVT Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def convert_pair(tree):\n",
    "    '''Given a data row of form [[parent,child,branch_length]]\n",
    "    return Nx21 array s.t the first 20 columns represent the input and the final 1 represents branch length'''\n",
    "    \n",
    "    #initialize\n",
    "    converted_tree = np.zeros((len(tree), 21))\n",
    "    i = 0\n",
    "    for pair in tree:\n",
    "        mut_array = barcode_det(pair[0], pair[1])[:,0:2].reshape(20,)\n",
    "        converted_pair = np.hstack((mut_array, np.array(pair[2])))#I don't care about final row\n",
    "        converted_tree[i, :] = converted_pair\n",
    "        i +=1\n",
    "    \n",
    "    return converted_tree\n",
    "#final preproccessing function\n",
    "def load_from_txt(data):\n",
    "    '''Given a .txt file of the data, return an array'''\n",
    "    loaded_data = []\n",
    "    \n",
    "    with open(data) as infile:\n",
    "        lines = infile.readlines()\n",
    "        for line in lines:\n",
    "            line_list = line[2:len(line)-4].split('], ')\n",
    "            new_line_list = []\n",
    "            for pair in line_list:#[parent,child,branchlength] objects\n",
    "                pair = pair[1:].split(', ')\n",
    "                new_pair = pair\n",
    "                new_pair[2] = float(pair[2])\n",
    "                new_line_list.append(new_pair)\n",
    "            loaded_data.append(new_line_list)\n",
    "            \n",
    "    return np.array(loaded_data)\n",
    "\n",
    "\n",
    "def preproccess(train_data, test_data, reference, split = 30):\n",
    "    '''\n",
    "    train_data/test_data - .txt files that reflect parent-child node pairs for each tree\n",
    "    reference - NEWICK format tree data (train/test derived from this set)\n",
    "    split - train/test split, dependant on guidelines\n",
    "    returns N x 2 Array s.t 1 column is a 10x3 array and another is the branch length\n",
    "    '''\n",
    "    DREAM_data = pd.read_csv(reference, sep = '\\t')\n",
    "    DREAM_train = DREAM_data[split:]\n",
    "    DREAM_test = DREAM_data[:split]\n",
    "\n",
    "    test_data_raw = load_from_txt(test_data)\n",
    "    train_data_raw = load_from_txt(train_data)\n",
    "\n",
    "    reformat_train = []\n",
    "    reformat_test = []\n",
    "\n",
    "    reformat_pair = [reformat_train, reformat_test]\n",
    "    DREAM_pair = [DREAM_train, DREAM_test]\n",
    "    data_pair = [train_data_raw, test_data_raw]\n",
    "\n",
    "\n",
    "    for k in range(2): #0 = train, 1 = test\n",
    "        for i in range(1, data_pair[k].shape[0]):\n",
    "            tree_row = data_pair[k][i]\n",
    "            tree_row = branch_ratio(tree_row, DREAM_pair[k], i)\n",
    "            reformat_row = convert_pair(tree_row)\n",
    "            reformat_pair[k].extend(reformat_row)#all pairs put together\n",
    "    \n",
    "    return reformat_pair\n",
    "\n",
    "all_data = preproccess('Data/trainingDataFinalOutput.txt',\n",
    "                       'Data/testingDataFinalOutput.txt',\n",
    "                       'Data/DREAM_data_intMEMOIR.csv')\n",
    "\n",
    "train_validate_data = np.vstack(all_data[0])\n",
    "#will mix up all of our trees, removing bias\n",
    "np.random.shuffle(train_validate_data)\n",
    "\n",
    "#tvt split is (908-386):386:386 for #pairs\n",
    "train_data = train_validate_data[:(908 - 386), :]#will split off 386 pairs for validation\n",
    "validate_data = train_validate_data[(908 - 386):, :]\n",
    "test_data = np.vstack(all_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Loader Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(data, batch_size = 1):\n",
    "    '''\n",
    "    Accepts data array of form Nx2 for the first column of input\n",
    "    and the 2nd column of ground truth.\n",
    "    Returns DataLoader object with specific batch_size\n",
    "    '''\n",
    "    data_input , data_label = torch.from_numpy(data[:, :20]).type(torch.FloatTensor),\\\n",
    "                              torch.from_numpy(data[:, 20]).type(torch.FloatTensor)\n",
    "    dataTensorSet = TensorDataset(data_input, data_label)\n",
    "    dataLoader = DataLoader(dataTensorSet, batch_size = batch_size)\n",
    "    \n",
    "    return dataLoader\n",
    "\n",
    "trainLoader = loader(train_data, batch_size = 32)\n",
    "validateLoader = loader(validate_data, batch_size = 32 * 2)\n",
    "testLoader = loader(test_data, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Definition\n",
    "<a id = 'model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    '''\n",
    "    1 layer FC, trained to find linear relationship between 2 types of mutations for 10 trits\n",
    "    and branch length\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(20, 1)\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter/extra function definition\n",
    "BRANCH_MODEL = model()\n",
    "LR = 1e-4\n",
    "EPOCHS = 400\n",
    "optimizer = optim.Adam(BRANCH_MODEL.parameters(), lr = LR)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "score = nn.MSELoss()#want to minimize this\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.85, patience = 2, verbose = True)\n",
    "\n",
    "model_save_path = 'saved_models/'\n",
    "best_model_path = os.path.join(model_save_path, 'Best_Brancher.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "<a id = 'train'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.027 | Validation Loss: 0.024 | Validation Score: 0.047 | \n",
      "Best model saved @ Epoch: 0, Score: 0.047\n",
      "Epoch: 1 | Train Loss: 0.027 | Validation Loss: 0.023 | Validation Score: 0.047 | \n",
      "Best model saved @ Epoch: 1, Score: 0.047\n",
      "Epoch: 2 | Train Loss: 0.026 | Validation Loss: 0.023 | Validation Score: 0.047 | \n",
      "Best model saved @ Epoch: 2, Score: 0.047\n",
      "Epoch: 3 | Train Loss: 0.026 | Validation Loss: 0.023 | Validation Score: 0.047 | \n",
      "Best model saved @ Epoch: 3, Score: 0.047\n",
      "Epoch: 4 | Train Loss: 0.026 | Validation Loss: 0.023 | Validation Score: 0.046 | \n",
      "Best model saved @ Epoch: 4, Score: 0.046\n",
      "Epoch: 5 | Train Loss: 0.026 | Validation Loss: 0.023 | Validation Score: 0.046 | \n",
      "Best model saved @ Epoch: 5, Score: 0.046\n",
      "Epoch: 6 | Train Loss: 0.025 | Validation Loss: 0.023 | Validation Score: 0.046 | \n",
      "Best model saved @ Epoch: 6, Score: 0.046\n",
      "Epoch: 7 | Train Loss: 0.025 | Validation Loss: 0.023 | Validation Score: 0.046 | \n",
      "Best model saved @ Epoch: 7, Score: 0.046\n",
      "Epoch: 8 | Train Loss: 0.025 | Validation Loss: 0.022 | Validation Score: 0.045 | \n",
      "Best model saved @ Epoch: 8, Score: 0.045\n",
      "Epoch: 9 | Train Loss: 0.025 | Validation Loss: 0.022 | Validation Score: 0.045 | \n",
      "Best model saved @ Epoch: 9, Score: 0.045\n",
      "Epoch: 10 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.045 | \n",
      "Best model saved @ Epoch: 10, Score: 0.045\n",
      "Epoch: 11 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.045 | \n",
      "Best model saved @ Epoch: 11, Score: 0.045\n",
      "Epoch: 12 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.045 | \n",
      "Best model saved @ Epoch: 12, Score: 0.045\n",
      "Epoch: 13 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 13, Score: 0.044\n",
      "Epoch: 14 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 14, Score: 0.044\n",
      "Epoch: 15 | Train Loss: 0.024 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 15, Score: 0.044\n",
      "Epoch: 16 | Train Loss: 0.023 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 16, Score: 0.044\n",
      "Epoch: 17 | Train Loss: 0.023 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 17, Score: 0.044\n",
      "Epoch: 18 | Train Loss: 0.023 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 18, Score: 0.044\n",
      "Epoch: 19 | Train Loss: 0.023 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 19, Score: 0.044\n",
      "Epoch: 20 | Train Loss: 0.023 | Validation Loss: 0.022 | Validation Score: 0.044 | \n",
      "Best model saved @ Epoch: 20, Score: 0.044\n",
      "Epoch: 21 | Train Loss: 0.023 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 21, Score: 0.043\n",
      "Epoch: 22 | Train Loss: 0.023 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 22, Score: 0.043\n",
      "Epoch: 23 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 23, Score: 0.043\n",
      "Epoch: 24 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 24, Score: 0.043\n",
      "Epoch: 25 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 25, Score: 0.043\n",
      "Epoch: 26 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 26, Score: 0.043\n",
      "Epoch: 27 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 27, Score: 0.043\n",
      "Epoch: 28 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.043 | \n",
      "Best model saved @ Epoch: 28, Score: 0.043\n",
      "Epoch: 29 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 29, Score: 0.042\n",
      "Epoch: 30 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 30, Score: 0.042\n",
      "Epoch: 31 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 31, Score: 0.042\n",
      "Epoch: 32 | Train Loss: 0.022 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 32, Score: 0.042\n",
      "Epoch: 33 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 33, Score: 0.042\n",
      "Epoch: 34 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 34, Score: 0.042\n",
      "Epoch: 35 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 35, Score: 0.042\n",
      "Epoch: 36 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 36, Score: 0.042\n",
      "Epoch: 37 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 37, Score: 0.042\n",
      "Epoch: 38 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 38, Score: 0.042\n",
      "Epoch: 39 | Train Loss: 0.021 | Validation Loss: 0.021 | Validation Score: 0.042 | \n",
      "Best model saved @ Epoch: 39, Score: 0.042\n",
      "Epoch: 40 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 40, Score: 0.041\n",
      "Epoch: 41 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 41, Score: 0.041\n",
      "Epoch: 42 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 42, Score: 0.041\n",
      "Epoch: 43 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 43, Score: 0.041\n",
      "Epoch: 44 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 44, Score: 0.041\n",
      "Epoch: 45 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 45, Score: 0.041\n",
      "Epoch: 46 | Train Loss: 0.021 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 46, Score: 0.041\n",
      "Epoch: 47 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 47, Score: 0.041\n",
      "Epoch: 48 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 48, Score: 0.041\n",
      "Epoch: 49 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 49, Score: 0.041\n",
      "Epoch: 50 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 50, Score: 0.041\n",
      "Epoch: 51 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 51, Score: 0.041\n",
      "Epoch: 52 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.041 | \n",
      "Best model saved @ Epoch: 52, Score: 0.041\n",
      "Epoch: 53 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 53, Score: 0.040\n",
      "Epoch: 54 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 54, Score: 0.040\n",
      "Epoch: 55 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 55, Score: 0.040\n",
      "Epoch: 56 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 56, Score: 0.040\n",
      "Epoch: 57 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 57, Score: 0.040\n",
      "Epoch: 58 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 58, Score: 0.040\n",
      "Epoch: 59 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 59, Score: 0.040\n",
      "Epoch: 60 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 60, Score: 0.040\n",
      "Epoch: 61 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 61, Score: 0.040\n",
      "Epoch: 62 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 62, Score: 0.040\n",
      "Epoch: 63 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 63, Score: 0.040\n",
      "Epoch: 64 | Train Loss: 0.020 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 64, Score: 0.040\n",
      "Epoch: 65 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 65, Score: 0.040\n",
      "Epoch: 66 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 66, Score: 0.040\n",
      "Epoch: 67 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 67, Score: 0.040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 68, Score: 0.040\n",
      "Epoch: 69 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 69, Score: 0.040\n",
      "Epoch: 70 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 70, Score: 0.040\n",
      "Epoch: 71 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.040 | \n",
      "Best model saved @ Epoch: 71, Score: 0.040\n",
      "Epoch: 72 | Train Loss: 0.019 | Validation Loss: 0.020 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 72, Score: 0.039\n",
      "Epoch: 73 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 73, Score: 0.039\n",
      "Epoch: 74 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 74, Score: 0.039\n",
      "Epoch: 75 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 75, Score: 0.039\n",
      "Epoch: 76 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 76, Score: 0.039\n",
      "Epoch: 77 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 77, Score: 0.039\n",
      "Epoch: 78 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 78, Score: 0.039\n",
      "Epoch: 79 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 79, Score: 0.039\n",
      "Epoch: 80 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 80, Score: 0.039\n",
      "Epoch: 81 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 81, Score: 0.039\n",
      "Epoch: 82 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 82, Score: 0.039\n",
      "Epoch: 83 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 83, Score: 0.039\n",
      "Epoch: 84 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 84, Score: 0.039\n",
      "Epoch: 85 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 85, Score: 0.039\n",
      "Epoch: 86 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 86, Score: 0.039\n",
      "Epoch: 87 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 87, Score: 0.039\n",
      "Epoch: 88 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 88, Score: 0.039\n",
      "Epoch: 89 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 89, Score: 0.039\n",
      "Epoch: 90 | Train Loss: 0.019 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 90, Score: 0.039\n",
      "Epoch: 91 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 91, Score: 0.039\n",
      "Epoch: 92 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 92, Score: 0.039\n",
      "Epoch: 93 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 93, Score: 0.039\n",
      "Epoch: 94 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 94, Score: 0.039\n",
      "Epoch: 95 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 95, Score: 0.039\n",
      "Epoch: 96 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 96, Score: 0.039\n",
      "Epoch: 97 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 97, Score: 0.039\n",
      "Epoch: 98 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 98, Score: 0.039\n",
      "Epoch: 99 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 99, Score: 0.039\n",
      "Epoch: 100 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 100, Score: 0.039\n",
      "Epoch: 101 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 101, Score: 0.039\n",
      "Epoch: 102 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 102, Score: 0.039\n",
      "Epoch: 103 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 103, Score: 0.039\n",
      "Epoch: 104 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 104, Score: 0.039\n",
      "Epoch: 105 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 105, Score: 0.039\n",
      "Epoch: 106 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 106, Score: 0.039\n",
      "Epoch: 107 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 107, Score: 0.039\n",
      "Epoch: 108 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.039 | \n",
      "Best model saved @ Epoch: 108, Score: 0.039\n",
      "Epoch: 109 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 109, Score: 0.038\n",
      "Epoch: 110 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 110, Score: 0.038\n",
      "Epoch: 111 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 111, Score: 0.038\n",
      "Epoch: 112 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 112, Score: 0.038\n",
      "Epoch: 113 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 113, Score: 0.038\n",
      "Epoch: 114 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 114, Score: 0.038\n",
      "Epoch: 115 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 115, Score: 0.038\n",
      "Epoch: 116 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 116, Score: 0.038\n",
      "Epoch: 117 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 117, Score: 0.038\n",
      "Epoch: 118 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 118, Score: 0.038\n",
      "Epoch: 119 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 119, Score: 0.038\n",
      "Epoch: 120 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 120, Score: 0.038\n",
      "Epoch: 121 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 121, Score: 0.038\n",
      "Epoch: 122 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 122, Score: 0.038\n",
      "Epoch: 123 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 123, Score: 0.038\n",
      "Epoch: 124 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 124, Score: 0.038\n",
      "Epoch: 125 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 125, Score: 0.038\n",
      "Epoch: 126 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 126, Score: 0.038\n",
      "Epoch: 127 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 127, Score: 0.038\n",
      "Epoch: 128 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 128, Score: 0.038\n",
      "Epoch: 129 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 129, Score: 0.038\n",
      "Epoch: 130 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 130, Score: 0.038\n",
      "Epoch: 131 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 131, Score: 0.038\n",
      "Epoch: 132 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 132, Score: 0.038\n",
      "Epoch: 133 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 133, Score: 0.038\n",
      "Epoch: 134 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 134, Score: 0.038\n",
      "Epoch: 135 | Train Loss: 0.018 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 135, Score: 0.038\n",
      "Epoch: 136 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 136, Score: 0.038\n",
      "Epoch: 137 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 137, Score: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 138, Score: 0.038\n",
      "Epoch: 139 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 139, Score: 0.038\n",
      "Epoch: 140 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 140, Score: 0.038\n",
      "Epoch: 141 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 141, Score: 0.038\n",
      "Epoch: 142 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 142, Score: 0.038\n",
      "Epoch: 143 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 143, Score: 0.038\n",
      "Epoch: 144 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 144, Score: 0.038\n",
      "Epoch: 145 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 145, Score: 0.038\n",
      "Epoch: 146 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 146, Score: 0.038\n",
      "Epoch: 147 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 147, Score: 0.038\n",
      "Epoch: 148 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 148, Score: 0.038\n",
      "Epoch: 149 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 149, Score: 0.038\n",
      "Epoch: 150 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 150, Score: 0.038\n",
      "Epoch: 151 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 151, Score: 0.038\n",
      "Epoch: 152 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 152, Score: 0.038\n",
      "Epoch: 153 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 153, Score: 0.038\n",
      "Epoch: 154 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 154, Score: 0.038\n",
      "Epoch: 155 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 155, Score: 0.038\n",
      "Epoch: 156 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 156, Score: 0.038\n",
      "Epoch: 157 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 157, Score: 0.038\n",
      "Epoch: 158 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 158, Score: 0.038\n",
      "Epoch: 159 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 159, Score: 0.038\n",
      "Epoch: 160 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 160, Score: 0.038\n",
      "Epoch: 161 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 161, Score: 0.038\n",
      "Epoch: 162 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 162, Score: 0.038\n",
      "Epoch: 163 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 163, Score: 0.038\n",
      "Epoch: 164 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 164, Score: 0.038\n",
      "Epoch: 165 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 165, Score: 0.038\n",
      "Epoch: 166 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 166, Score: 0.038\n",
      "Epoch: 167 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 167, Score: 0.038\n",
      "Epoch: 168 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 168, Score: 0.038\n",
      "Epoch: 169 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 169, Score: 0.038\n",
      "Epoch: 170 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 170, Score: 0.038\n",
      "Epoch: 171 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 171, Score: 0.038\n",
      "Epoch: 172 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 172, Score: 0.038\n",
      "Epoch: 173 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 173, Score: 0.038\n",
      "Epoch: 174 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 174, Score: 0.038\n",
      "Epoch: 175 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 175, Score: 0.038\n",
      "Epoch: 176 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 176, Score: 0.038\n",
      "Epoch: 177 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 177, Score: 0.038\n",
      "Epoch: 178 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 178, Score: 0.038\n",
      "Epoch: 179 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 179, Score: 0.038\n",
      "Epoch: 180 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 180, Score: 0.038\n",
      "Epoch: 181 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 181, Score: 0.038\n",
      "Epoch: 182 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 182, Score: 0.038\n",
      "Epoch: 183 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 183, Score: 0.038\n",
      "Epoch: 184 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 184, Score: 0.038\n",
      "Epoch: 185 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 185, Score: 0.038\n",
      "Epoch: 186 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 186, Score: 0.038\n",
      "Epoch: 187 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 187, Score: 0.038\n",
      "Epoch: 188 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 188, Score: 0.038\n",
      "Epoch: 189 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 189, Score: 0.038\n",
      "Epoch: 190 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 190, Score: 0.038\n",
      "Epoch: 191 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 191, Score: 0.038\n",
      "Epoch: 192 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 192, Score: 0.038\n",
      "Epoch: 193 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 193, Score: 0.038\n",
      "Epoch: 194 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 194, Score: 0.038\n",
      "Epoch: 195 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 195, Score: 0.038\n",
      "Epoch: 196 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 196, Score: 0.038\n",
      "Epoch: 197 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 197, Score: 0.038\n",
      "Epoch: 198 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 198, Score: 0.038\n",
      "Epoch: 199 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 199, Score: 0.038\n",
      "Epoch: 200 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 200, Score: 0.038\n",
      "Epoch: 201 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 201, Score: 0.038\n",
      "Epoch: 202 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 202, Score: 0.038\n",
      "Epoch: 203 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 203, Score: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 204, Score: 0.038\n",
      "Epoch: 205 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 205, Score: 0.038\n",
      "Epoch: 206 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 206, Score: 0.038\n",
      "Epoch: 207 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 207, Score: 0.038\n",
      "Epoch: 208 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 208, Score: 0.038\n",
      "Epoch: 209 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 209, Score: 0.038\n",
      "Epoch: 210 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 210, Score: 0.038\n",
      "Epoch: 211 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 211, Score: 0.038\n",
      "Epoch: 212 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 212, Score: 0.038\n",
      "Epoch: 213 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 213, Score: 0.038\n",
      "Epoch: 214 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 214, Score: 0.038\n",
      "Epoch: 215 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 215, Score: 0.038\n",
      "Epoch: 216 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 216, Score: 0.038\n",
      "Epoch: 217 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 217, Score: 0.038\n",
      "Epoch: 218 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 218, Score: 0.038\n",
      "Epoch: 219 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 219, Score: 0.038\n",
      "Epoch: 220 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 220, Score: 0.038\n",
      "Epoch: 221 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 221, Score: 0.038\n",
      "Epoch: 222 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 222, Score: 0.038\n",
      "Epoch: 223 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 223, Score: 0.038\n",
      "Epoch: 224 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 224, Score: 0.038\n",
      "Epoch: 225 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 225, Score: 0.038\n",
      "Epoch: 226 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 226, Score: 0.038\n",
      "Epoch: 227 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 227, Score: 0.038\n",
      "Epoch: 228 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 228, Score: 0.038\n",
      "Epoch: 229 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 229, Score: 0.038\n",
      "Epoch: 230 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 230, Score: 0.038\n",
      "Epoch: 231 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 231, Score: 0.038\n",
      "Epoch: 232 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 232, Score: 0.038\n",
      "Epoch: 233 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 233, Score: 0.038\n",
      "Epoch: 234 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 234, Score: 0.038\n",
      "Epoch: 235 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 235, Score: 0.038\n",
      "Epoch: 236 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 236, Score: 0.038\n",
      "Epoch: 237 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 237, Score: 0.038\n",
      "Epoch: 238 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 238, Score: 0.038\n",
      "Epoch: 239 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 239, Score: 0.038\n",
      "Epoch: 240 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 240, Score: 0.038\n",
      "Epoch: 241 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 241, Score: 0.038\n",
      "Epoch: 242 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 242, Score: 0.038\n",
      "Epoch: 243 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 243, Score: 0.038\n",
      "Epoch: 244 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 244, Score: 0.038\n",
      "Epoch: 245 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 245, Score: 0.038\n",
      "Epoch: 246 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 246, Score: 0.038\n",
      "Epoch: 247 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 247, Score: 0.038\n",
      "Epoch: 248 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 248, Score: 0.038\n",
      "Epoch: 249 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 249, Score: 0.038\n",
      "Epoch: 250 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 250, Score: 0.038\n",
      "Epoch: 251 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 251, Score: 0.038\n",
      "Epoch: 252 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 252, Score: 0.038\n",
      "Epoch: 253 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 253, Score: 0.038\n",
      "Epoch: 254 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 254, Score: 0.038\n",
      "Epoch: 255 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 255, Score: 0.038\n",
      "Epoch: 256 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 256, Score: 0.038\n",
      "Epoch: 257 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 257, Score: 0.038\n",
      "Epoch: 258 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 258, Score: 0.038\n",
      "Epoch: 259 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 259, Score: 0.038\n",
      "Epoch: 260 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 260, Score: 0.038\n",
      "Epoch: 261 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 261, Score: 0.038\n",
      "Epoch: 262 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 262, Score: 0.038\n",
      "Epoch: 263 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 263, Score: 0.038\n",
      "Epoch: 264 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 264, Score: 0.038\n",
      "Epoch: 265 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 265, Score: 0.038\n",
      "Epoch: 266 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 266, Score: 0.038\n",
      "Epoch: 267 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 267, Score: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 268 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 268, Score: 0.038\n",
      "Epoch: 269 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 269, Score: 0.038\n",
      "Epoch: 270 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 270, Score: 0.038\n",
      "Epoch: 271 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 271, Score: 0.038\n",
      "Epoch: 272 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 272, Score: 0.038\n",
      "Epoch: 273 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 273, Score: 0.038\n",
      "Epoch: 274 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 274, Score: 0.038\n",
      "Epoch: 275 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 275, Score: 0.038\n",
      "Epoch: 276 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 276, Score: 0.038\n",
      "Epoch: 277 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 277, Score: 0.038\n",
      "Epoch: 278 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 278, Score: 0.038\n",
      "Epoch: 279 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 279, Score: 0.038\n",
      "Epoch: 280 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 280, Score: 0.038\n",
      "Epoch: 281 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 281, Score: 0.038\n",
      "Epoch: 282 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 282, Score: 0.038\n",
      "Epoch: 283 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 283, Score: 0.038\n",
      "Epoch: 284 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 284, Score: 0.038\n",
      "Epoch: 285 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 285, Score: 0.038\n",
      "Epoch: 286 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 286, Score: 0.038\n",
      "Epoch   288: reducing learning rate of group 0 to 8.5000e-05.\n",
      "Epoch: 287 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 287, Score: 0.038\n",
      "Epoch: 288 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 288, Score: 0.038\n",
      "Epoch: 289 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 289, Score: 0.038\n",
      "Epoch: 290 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 290, Score: 0.038\n",
      "Epoch   292: reducing learning rate of group 0 to 7.2250e-05.\n",
      "Epoch: 291 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 291, Score: 0.038\n",
      "Epoch: 292 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 292, Score: 0.038\n",
      "Epoch: 293 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 293, Score: 0.038\n",
      "Epoch: 294 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 294, Score: 0.038\n",
      "Epoch: 295 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 295, Score: 0.038\n",
      "Epoch   297: reducing learning rate of group 0 to 6.1413e-05.\n",
      "Epoch: 296 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 296, Score: 0.038\n",
      "Epoch: 297 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 297, Score: 0.038\n",
      "Epoch: 298 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 298, Score: 0.038\n",
      "Epoch: 299 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 299, Score: 0.038\n",
      "Epoch: 300 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 300, Score: 0.038\n",
      "Epoch: 301 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 301, Score: 0.038\n",
      "Epoch   303: reducing learning rate of group 0 to 5.2201e-05.\n",
      "Epoch: 302 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 302, Score: 0.038\n",
      "Epoch: 303 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 303, Score: 0.038\n",
      "Epoch: 304 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 304, Score: 0.038\n",
      "Epoch   306: reducing learning rate of group 0 to 4.4371e-05.\n",
      "Epoch: 305 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 305, Score: 0.038\n",
      "Epoch: 306 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 306, Score: 0.038\n",
      "Epoch: 307 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 307, Score: 0.038\n",
      "Epoch: 308 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 308, Score: 0.038\n",
      "Epoch   310: reducing learning rate of group 0 to 3.7715e-05.\n",
      "Epoch: 309 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 309, Score: 0.038\n",
      "Epoch: 310 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 310, Score: 0.038\n",
      "Epoch: 311 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 311, Score: 0.038\n",
      "Epoch   313: reducing learning rate of group 0 to 3.2058e-05.\n",
      "Epoch: 312 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 312, Score: 0.038\n",
      "Epoch: 313 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 313, Score: 0.038\n",
      "Epoch: 314 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 314, Score: 0.038\n",
      "Epoch   316: reducing learning rate of group 0 to 2.7249e-05.\n",
      "Epoch: 315 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 315, Score: 0.038\n",
      "Epoch: 316 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 316, Score: 0.038\n",
      "Epoch: 317 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 317, Score: 0.038\n",
      "Epoch: 318 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 318, Score: 0.038\n",
      "Epoch: 319 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 319, Score: 0.038\n",
      "Epoch: 320 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 320, Score: 0.038\n",
      "Epoch   322: reducing learning rate of group 0 to 2.3162e-05.\n",
      "Epoch: 321 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 321, Score: 0.038\n",
      "Epoch: 322 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 322, Score: 0.038\n",
      "Epoch: 323 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 323, Score: 0.038\n",
      "Epoch   325: reducing learning rate of group 0 to 1.9687e-05.\n",
      "Epoch: 324 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 324, Score: 0.038\n",
      "Epoch: 325 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 325, Score: 0.038\n",
      "Epoch: 326 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 326, Score: 0.038\n",
      "Epoch   328: reducing learning rate of group 0 to 1.6734e-05.\n",
      "Epoch: 327 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 327, Score: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 328, Score: 0.038\n",
      "Epoch: 329 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 329, Score: 0.038\n",
      "Epoch   331: reducing learning rate of group 0 to 1.4224e-05.\n",
      "Epoch: 330 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 330, Score: 0.038\n",
      "Epoch: 331 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 331, Score: 0.038\n",
      "Epoch: 332 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 332, Score: 0.038\n",
      "Epoch   334: reducing learning rate of group 0 to 1.2091e-05.\n",
      "Epoch: 333 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 333, Score: 0.038\n",
      "Epoch: 334 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 334, Score: 0.038\n",
      "Epoch: 335 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 335, Score: 0.038\n",
      "Epoch   337: reducing learning rate of group 0 to 1.0277e-05.\n",
      "Epoch: 336 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 336, Score: 0.038\n",
      "Epoch: 337 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 337, Score: 0.038\n",
      "Epoch: 338 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 338, Score: 0.038\n",
      "Epoch   340: reducing learning rate of group 0 to 8.7354e-06.\n",
      "Epoch: 339 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 339, Score: 0.038\n",
      "Epoch: 340 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 340, Score: 0.038\n",
      "Epoch: 341 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 341, Score: 0.038\n",
      "Epoch   343: reducing learning rate of group 0 to 7.4251e-06.\n",
      "Epoch: 342 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 342, Score: 0.038\n",
      "Epoch: 343 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 343, Score: 0.038\n",
      "Epoch: 344 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 344, Score: 0.038\n",
      "Epoch   346: reducing learning rate of group 0 to 6.3113e-06.\n",
      "Epoch: 345 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 345, Score: 0.038\n",
      "Epoch: 346 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 346, Score: 0.038\n",
      "Epoch: 347 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 347, Score: 0.038\n",
      "Epoch   349: reducing learning rate of group 0 to 5.3646e-06.\n",
      "Epoch: 348 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 348, Score: 0.038\n",
      "Epoch: 349 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 349, Score: 0.038\n",
      "Epoch: 350 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 350, Score: 0.038\n",
      "Epoch: 351 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 351, Score: 0.038\n",
      "Epoch   353: reducing learning rate of group 0 to 4.5599e-06.\n",
      "Epoch: 352 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 352, Score: 0.038\n",
      "Epoch: 353 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 353, Score: 0.038\n",
      "Epoch: 354 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 354, Score: 0.038\n",
      "Epoch   356: reducing learning rate of group 0 to 3.8760e-06.\n",
      "Epoch: 355 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 355, Score: 0.038\n",
      "Epoch: 356 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 356, Score: 0.038\n",
      "Epoch: 357 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 357, Score: 0.038\n",
      "Epoch   359: reducing learning rate of group 0 to 3.2946e-06.\n",
      "Epoch: 358 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 358, Score: 0.038\n",
      "Epoch: 359 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 359, Score: 0.038\n",
      "Epoch: 360 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 360, Score: 0.038\n",
      "Epoch   362: reducing learning rate of group 0 to 2.8004e-06.\n",
      "Epoch: 361 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 361, Score: 0.038\n",
      "Epoch: 362 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 362, Score: 0.038\n",
      "Epoch: 363 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 363, Score: 0.038\n",
      "Epoch   365: reducing learning rate of group 0 to 2.3803e-06.\n",
      "Epoch: 364 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 364, Score: 0.038\n",
      "Epoch: 365 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 365, Score: 0.038\n",
      "Epoch: 366 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 366, Score: 0.038\n",
      "Epoch   368: reducing learning rate of group 0 to 2.0233e-06.\n",
      "Epoch: 367 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 367, Score: 0.038\n",
      "Epoch: 368 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 368, Score: 0.038\n",
      "Epoch: 369 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 369, Score: 0.038\n",
      "Epoch   371: reducing learning rate of group 0 to 1.7198e-06.\n",
      "Epoch: 370 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 370, Score: 0.038\n",
      "Epoch: 371 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 371, Score: 0.038\n",
      "Epoch: 372 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 372, Score: 0.038\n",
      "Epoch   374: reducing learning rate of group 0 to 1.4618e-06.\n",
      "Epoch: 373 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 373, Score: 0.038\n",
      "Epoch: 374 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 374, Score: 0.038\n",
      "Epoch: 375 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 375, Score: 0.038\n",
      "Epoch   377: reducing learning rate of group 0 to 1.2425e-06.\n",
      "Epoch: 376 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 376, Score: 0.038\n",
      "Epoch: 377 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 377, Score: 0.038\n",
      "Epoch: 378 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 378, Score: 0.038\n",
      "Epoch   380: reducing learning rate of group 0 to 1.0562e-06.\n",
      "Epoch: 379 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 379, Score: 0.038\n",
      "Epoch: 380 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 380, Score: 0.038\n",
      "Epoch: 381 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 381, Score: 0.038\n",
      "Epoch   383: reducing learning rate of group 0 to 8.9774e-07.\n",
      "Epoch: 382 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 382, Score: 0.038\n",
      "Epoch: 383 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 383, Score: 0.038\n",
      "Epoch: 384 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 384, Score: 0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   386: reducing learning rate of group 0 to 7.6308e-07.\n",
      "Epoch: 385 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 385, Score: 0.038\n",
      "Epoch: 386 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 386, Score: 0.038\n",
      "Epoch: 387 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 387, Score: 0.038\n",
      "Epoch   389: reducing learning rate of group 0 to 6.4861e-07.\n",
      "Epoch: 388 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Epoch: 389 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 389, Score: 0.038\n",
      "Epoch: 390 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 390, Score: 0.038\n",
      "Epoch   392: reducing learning rate of group 0 to 5.5132e-07.\n",
      "Epoch: 391 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 391, Score: 0.038\n",
      "Epoch: 392 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Epoch: 393 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 393, Score: 0.038\n",
      "Epoch   395: reducing learning rate of group 0 to 4.6862e-07.\n",
      "Epoch: 394 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 394, Score: 0.038\n",
      "Epoch: 395 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Epoch: 396 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 396, Score: 0.038\n",
      "Epoch   398: reducing learning rate of group 0 to 3.9833e-07.\n",
      "Epoch: 397 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Epoch: 398 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Epoch: 399 | Train Loss: 0.017 | Validation Loss: 0.019 | Validation Score: 0.038 | \n",
      "Best model saved @ Epoch: 399, Score: 0.038\n"
     ]
    }
   ],
   "source": [
    "last_score = np.inf\n",
    "history = {'train_epoch_loss': [], 'validate_epoch_loss': []}\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_epoch_loss, validate_epoch_loss, epoch_score, batch_n = 0, 0, 0, 0\n",
    "    ### TRAIN ###\n",
    "    BRANCH_MODEL.train()\n",
    "    for batch_i, (train_input, train_label) in enumerate(trainLoader):\n",
    "        batch_n += 1\n",
    "        predicted_label = BRANCH_MODEL(train_input).view(train_input.shape[0])\n",
    "        #reset the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #compute loss\n",
    "        loss = criterion(predicted_label, train_label)\n",
    "        train_epoch_loss += loss\n",
    "        \n",
    "        #backpropagate loss\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_epoch_loss = train_epoch_loss / batch_n #average Smooth L1\n",
    "    \n",
    "    ### VALIDATE ###\n",
    "    #NOTE: BATCH_SIZE = SAMPLE SPACE, so \n",
    "    batch_n = 0\n",
    "    BRANCH_MODEL.eval()\n",
    "    for batch_i, (validate_input, validate_label) in enumerate(validateLoader):\n",
    "        batch_n += 1\n",
    "        predicted_label = BRANCH_MODEL(train_input)\n",
    "\n",
    "        #compute loss\n",
    "        loss = criterion(predicted_label, validate_label)\n",
    "        validate_epoch_loss += loss\n",
    "\n",
    "        #compute score\n",
    "        batch_score = score(predicted_label, validate_label)\n",
    "        epoch_score += batch_score\n",
    "        \n",
    "    validate_epoch_loss = validate_epoch_loss/ batch_n\n",
    "    epoch_score = epoch_score / batch_n\n",
    "    \n",
    "    history['train_epoch_loss'].append(train_epoch_loss)\n",
    "    history['validate_epoch_loss'].append(validate_epoch_loss)        \n",
    "    \n",
    "    #reduce LR On Plateau\n",
    "    scheduler.step(validate_epoch_loss)\n",
    "    \n",
    "    #print logs\n",
    "    print(f'Epoch: {epoch} | ', end = '')\n",
    "    print(f'Train Loss: {train_epoch_loss:.3f} | ', end = '')\n",
    "    print(f'Validation Loss: {validate_epoch_loss:.3f} | ', end = '')\n",
    "    print(f'Validation Score: {epoch_score:.3f} | ', end = '')\n",
    "    #save best model\n",
    "    if last_score > epoch_score:\n",
    "        torch.save(BRANCH_MODEL.state_dict(), best_model_path)\n",
    "        last_score = epoch_score\n",
    "        print(f'\\nBest model saved @ Epoch: {epoch}, Score: {epoch_score:.3f}')\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "<a id = 'eval'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show some results\n",
    "plt.plot(history['train_epoch_loss'])\n",
    "plt.plot(history['validate_epoch_loss'])\n",
    "plt.legend(['Train Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Smooth L1 Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Error: 0.050\n"
     ]
    }
   ],
   "source": [
    "#evaluate performance on test set\n",
    "#### Testing ####\n",
    "state_dict = torch.load(os.path.join(model_save_path, 'Best_Brancher.pth'))\n",
    "BRANCH_MODEL.load_state_dict(state_dict)\n",
    "BRANCH_MODEL.eval()\n",
    "ERROR, batch_n = 0,0\n",
    "for i, (test_input, test_label) in enumerate(testLoader):\n",
    "    batch_n += 1\n",
    "    predicted_label = BRANCH_MODEL(test_input).view(1)\n",
    "    test_error = score(predicted_label, test_label)\n",
    "    ERROR += test_error\n",
    "    \n",
    "ERROR = ERROR / batch_n\n",
    "\n",
    "print(f'Overall Error: {ERROR:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Branch Function Setup\n",
    "<a id = 'function'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2867802083492279\n"
     ]
    }
   ],
   "source": [
    "def pair_to_length(pair, model_source = best_model_path):\n",
    "    BL_Model = model()\n",
    "    BL_Model.load_state_dict(torch.load(best_model_path))\n",
    "    BL_Model.eval()\n",
    "    converted_pair = barcode_det(pair[0], pair[1])[:,0:2].reshape(20,)\n",
    "    pair_torch = torch.from_numpy(converted_pair).type(torch.FloatTensor)\n",
    "    \n",
    "    return BL_Model(pair_torch).item()\n",
    "\n",
    "#test\n",
    "parent = '1'*10\n",
    "child = '1'*5 + '' + '1'*4\n",
    "pair = [parent, child]\n",
    "print(pair_to_length(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child: 0111111111 | BL : 0.29841\n",
      "\n",
      "Child: 2111111111 | BL : 0.28130\n",
      "\n",
      "Child: 1011111111 | BL : 0.19965\n",
      "\n",
      "Child: 1211111111 | BL : 0.28782\n",
      "\n",
      "Child: 1101111111 | BL : 0.19436\n",
      "\n",
      "Child: 1121111111 | BL : 0.19341\n",
      "\n",
      "Child: 1110111111 | BL : 0.21913\n",
      "\n",
      "Child: 1112111111 | BL : 0.25191\n",
      "\n",
      "Child: 1111011111 | BL : 0.20914\n",
      "\n",
      "Child: 1111211111 | BL : 0.26638\n",
      "\n",
      "Child: 1111101111 | BL : 0.32115\n",
      "\n",
      "Child: 1111121111 | BL : 0.28678\n",
      "\n",
      "Child: 1111110111 | BL : 0.23714\n",
      "\n",
      "Child: 1111112111 | BL : 0.19966\n",
      "\n",
      "Child: 1111111011 | BL : 0.24917\n",
      "\n",
      "Child: 1111111211 | BL : 0.22848\n",
      "\n",
      "Child: 1111111101 | BL : 0.26509\n",
      "\n",
      "Child: 1111111121 | BL : 0.24193\n",
      "\n",
      "Child: 1111111110 | BL : 0.16276\n",
      "\n",
      "Child: 1111111112 | BL : 0.12832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "parent = '1'*10\n",
    "for i in range(10):\n",
    "    for j in ['0','2']:\n",
    "        child = '1'*(i) + j + '1'*(9 - i)\n",
    "        pair = [parent, child]\n",
    "        BL = pair_to_length(pair)\n",
    "        print(f'Child: {child} | ', end = '')\n",
    "        print(f'BL : {BL:.5f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
